{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60ffe6e7-b52b-4c39-b2b6-7c39cc26ee45",
   "metadata": {},
   "source": [
    "# AI-scientist の LLMLinks を用いた実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0a04d32-593a-4d86-843f-4ebdabcc8cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmlinks.llm_client import LLMClient\n",
    "from llmlinks.llm.openai_model import OpenAILLM\n",
    "from llmlinks.link import LLMLinkBase\n",
    "from llmlinks.compiler import LLMCompiler, CompiledLLMLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "524b55ae-6f3b-4c1e-9b27-4fb55b9b7237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'こんにちは！今日はどんなお手伝いをしましょうか？'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_compiler = OpenAILLM(model='gpt-4o-2024-08-06', temperature=0.2)\n",
    "llm_link = OpenAILLM(model='gpt-4o-2024-08-06', temperature=0.7)\n",
    "llm_link('こんにちは！')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21df1629-8d43-402b-8f45-d5e5eb9f5bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler = LLMCompiler(llm_compiler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5548b035-b927-4cec-a332-f7366c93cecd",
   "metadata": {},
   "source": [
    "## Demo task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1f3fc83-55ad-41ca-b28a-4c3c89e5a9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_description = '''\n",
    "You are an ambitious AI PhD student who is looking to publish a paper that will contribute significantly to the field.\n",
    "You are given the following file to work with, that trains a low-dimensional diffusion model on 4 different 2D datasets. The diffusion model is based on DDPM. Particularly interesting ideas would involve controllable generation, e.g. biased towards different modes of the data, or new encodings for low-dimensional data aside from sinusoidal encodings.\n",
    "'''.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0920b37f-2ac7-4e9b-aa9c-11ad6cc998f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_code = '''\n",
    "# This file trains a DDPM diffusion model on 2D datasets.\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import time\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import npeet.entropy_estimators as ee\n",
    "import pickle\n",
    "import pathlib\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from ema_pytorch import EMA\n",
    "\n",
    "import datasets\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class SinusoidalEmbedding(nn.Module):\n",
    "    def __init__(self, dim: int, scale: float = 1.0):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.scale = scale\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = x * self.scale\n",
    "        half_dim = self.dim // 2\n",
    "        emb = torch.log(torch.Tensor([10000.0])) / (half_dim - 1)\n",
    "        emb = torch.exp(-emb * torch.arange(half_dim)).to(device)\n",
    "        emb = x.unsqueeze(-1) * emb.unsqueeze(0)\n",
    "        emb = torch.cat((torch.sin(emb), torch.cos(emb)), dim=-1)\n",
    "        return emb\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, width: int):\n",
    "        super().__init__()\n",
    "        self.ff = nn.Linear(width, width)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return x + self.ff(self.act(x))\n",
    "\n",
    "\n",
    "class MLPDenoiser(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            embedding_dim: int = 128,\n",
    "            hidden_dim: int = 256,\n",
    "            hidden_layers: int = 3,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.time_mlp = SinusoidalEmbedding(embedding_dim)\n",
    "        # sinusoidal embeddings help capture high-frequency patterns for low-dim data\n",
    "        self.input_mlp1 = SinusoidalEmbedding(embedding_dim, scale=25.0)\n",
    "        self.input_mlp2 = SinusoidalEmbedding(embedding_dim, scale=25.0)\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(embedding_dim * 3, hidden_dim),\n",
    "            *[ResidualBlock(hidden_dim) for _ in range(hidden_layers)],\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        x1_emb = self.input_mlp1(x[:, 0])\n",
    "        x2_emb = self.input_mlp2(x[:, 1])\n",
    "        t_emb = self.time_mlp(t)\n",
    "        emb = torch.cat([x1_emb, x2_emb, t_emb], dim=-1)\n",
    "        return self.network(emb)\n",
    "\n",
    "\n",
    "class NoiseScheduler():\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_timesteps=1000,\n",
    "            beta_start=0.0001,\n",
    "            beta_end=0.02,\n",
    "            beta_schedule=\"linear\",\n",
    "    ):\n",
    "        self.num_timesteps = num_timesteps\n",
    "        if beta_schedule == \"linear\":\n",
    "            self.betas = torch.linspace(\n",
    "                beta_start, beta_end, num_timesteps, dtype=torch.float32).to(device)\n",
    "        elif beta_schedule == \"quadratic\":\n",
    "            self.betas = (torch.linspace(\n",
    "                beta_start ** 0.5, beta_end ** 0.5, num_timesteps, dtype=torch.float32) ** 2).to(device)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown beta schedule: {beta_schedule}\")\n",
    "\n",
    "        self.alphas = 1.0 - self.betas\n",
    "        self.alphas_cumprod = torch.cumprod(self.alphas, axis=0).to(device)\n",
    "        self.alphas_cumprod_prev = F.pad(self.alphas_cumprod[:-1], (1, 0), value=1.).to(device)\n",
    "\n",
    "        # required for self.add_noise\n",
    "        self.sqrt_alphas_cumprod = (self.alphas_cumprod ** 0.5).to(device)\n",
    "        self.sqrt_one_minus_alphas_cumprod = ((1 - self.alphas_cumprod) ** 0.5).to(device)\n",
    "\n",
    "        # required for reconstruct_x0\n",
    "        self.sqrt_inv_alphas_cumprod = torch.sqrt(1 / self.alphas_cumprod).to(device)\n",
    "        self.sqrt_inv_alphas_cumprod_minus_one = torch.sqrt(\n",
    "            1 / self.alphas_cumprod - 1).to(device)\n",
    "\n",
    "        # required for q_posterior\n",
    "        self.posterior_mean_coef1 = self.betas * torch.sqrt(self.alphas_cumprod_prev) / (1. - self.alphas_cumprod).to(\n",
    "            device)\n",
    "        self.posterior_mean_coef2 = ((1. - self.alphas_cumprod_prev) * torch.sqrt(self.alphas) / (\n",
    "                1. - self.alphas_cumprod)).to(device)\n",
    "\n",
    "    def reconstruct_x0(self, x_t, t, noise):\n",
    "        s1 = self.sqrt_inv_alphas_cumprod[t]\n",
    "        s2 = self.sqrt_inv_alphas_cumprod_minus_one[t]\n",
    "        s1 = s1.reshape(-1, 1)\n",
    "        s2 = s2.reshape(-1, 1)\n",
    "        return s1 * x_t - s2 * noise\n",
    "\n",
    "    def q_posterior(self, x_0, x_t, t):\n",
    "        s1 = self.posterior_mean_coef1[t]\n",
    "        s2 = self.posterior_mean_coef2[t]\n",
    "        s1 = s1.reshape(-1, 1)\n",
    "        s2 = s2.reshape(-1, 1)\n",
    "        mu = s1 * x_0 + s2 * x_t\n",
    "        return mu\n",
    "\n",
    "    def get_variance(self, t):\n",
    "        if t == 0:\n",
    "            return 0\n",
    "\n",
    "        variance = self.betas[t] * (1. - self.alphas_cumprod_prev[t]) / (1. - self.alphas_cumprod[t])\n",
    "        variance = variance.clip(1e-20)\n",
    "        return variance\n",
    "\n",
    "    def step(self, model_output, timestep, sample):\n",
    "        t = timestep\n",
    "        pred_original_sample = self.reconstruct_x0(sample, t, model_output)\n",
    "        pred_prev_sample = self.q_posterior(pred_original_sample, sample, t)\n",
    "\n",
    "        variance = 0\n",
    "        if t > 0:\n",
    "            noise = torch.randn_like(model_output)\n",
    "            variance = (self.get_variance(t) ** 0.5) * noise\n",
    "\n",
    "        pred_prev_sample = pred_prev_sample + variance\n",
    "\n",
    "        return pred_prev_sample\n",
    "\n",
    "    def add_noise(self, x_start, x_noise, timesteps):\n",
    "        s1 = self.sqrt_alphas_cumprod[timesteps]\n",
    "        s2 = self.sqrt_one_minus_alphas_cumprod[timesteps]\n",
    "\n",
    "        s1 = s1.reshape(-1, 1)\n",
    "        s2 = s2.reshape(-1, 1)\n",
    "\n",
    "        return s1 * x_start + s2 * x_noise\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_timesteps\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--train_batch_size\", type=int, default=256)\n",
    "    parser.add_argument(\"--eval_batch_size\", type=int, default=10000)\n",
    "    parser.add_argument(\"--learning_rate\", type=float, default=3e-4)\n",
    "    parser.add_argument(\"--num_timesteps\", type=int, default=100)\n",
    "    parser.add_argument(\"--num_train_steps\", type=int, default=10000)\n",
    "    parser.add_argument(\"--beta_schedule\", type=str, default=\"linear\", choices=[\"linear\", \"quadratic\"])\n",
    "    parser.add_argument(\"--embedding_dim\", type=int, default=128)\n",
    "    parser.add_argument(\"--hidden_size\", type=int, default=256)\n",
    "    parser.add_argument(\"--hidden_layers\", type=int, default=3)\n",
    "    parser.add_argument(\"--out_dir\", type=str, default=\"run_0\")\n",
    "    config = parser.parse_args()\n",
    "\n",
    "    final_infos = {}\n",
    "    all_results = {}\n",
    "\n",
    "    pathlib.Path(config.out_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for dataset_name in [\"circle\", \"dino\", \"line\", \"moons\"]:\n",
    "        dataset = datasets.get_dataset(dataset_name, n=100000)\n",
    "        dataloader = DataLoader(dataset, batch_size=config.train_batch_size, shuffle=True)\n",
    "\n",
    "        model = MLPDenoiser(\n",
    "            embedding_dim=config.embedding_dim,\n",
    "            hidden_dim=config.hidden_size,\n",
    "            hidden_layers=config.hidden_layers,\n",
    "        ).to(device)\n",
    "        ema_model = EMA(model, beta=0.995, update_every=10).to(device)\n",
    "\n",
    "        noise_scheduler = NoiseScheduler(num_timesteps=config.num_timesteps, beta_schedule=config.beta_schedule)\n",
    "\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            model.parameters(),\n",
    "            lr=config.learning_rate,\n",
    "        )\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=config.num_train_steps)\n",
    "        train_losses = []\n",
    "        print(\"Training model...\")\n",
    "\n",
    "        model.train()\n",
    "        global_step = 0\n",
    "        progress_bar = tqdm(total=config.num_train_steps, mininterval=10, disable=True)\n",
    "        progress_bar.set_description(\"Training\")\n",
    "\n",
    "        start_time = time.time()\n",
    "        while global_step < config.num_train_steps:\n",
    "            for batch in dataloader:\n",
    "                if global_step >= config.num_train_steps:\n",
    "                    break\n",
    "                batch = batch[0].to(device)\n",
    "                noise = torch.randn(batch.shape).to(device)\n",
    "                timesteps = torch.randint(\n",
    "                    0, noise_scheduler.num_timesteps, (batch.shape[0],)\n",
    "                ).long().to(device)\n",
    "\n",
    "                noisy = noise_scheduler.add_noise(batch, noise, timesteps)\n",
    "                noise_pred = model(noisy, timesteps)\n",
    "                loss = F.mse_loss(noise_pred, noise)\n",
    "                loss.backward()\n",
    "\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                ema_model.update()\n",
    "\n",
    "                scheduler.step()\n",
    "                progress_bar.update(1)\n",
    "                logs = {\"loss\": loss.detach().item()}\n",
    "                train_losses.append(loss.detach().item())\n",
    "                progress_bar.set_postfix(**logs)\n",
    "                global_step += 1\n",
    "\n",
    "        progress_bar.close()\n",
    "        end_time = time.time()\n",
    "        training_time = end_time - start_time\n",
    "\n",
    "        # Eval loss\n",
    "        model.eval()\n",
    "        eval_losses = []\n",
    "        for batch in dataloader:\n",
    "            batch = batch[0].to(device)\n",
    "            noise = torch.randn(batch.shape).to(device)\n",
    "            timesteps = torch.randint(\n",
    "                0, noise_scheduler.num_timesteps, (batch.shape[0],)\n",
    "            ).long().to(device)\n",
    "            noisy = noise_scheduler.add_noise(batch, noise, timesteps)\n",
    "            noise_pred = model(noisy, timesteps)\n",
    "            loss = F.mse_loss(noise_pred, noise)\n",
    "            eval_losses.append(loss.detach().item())\n",
    "        eval_loss = np.mean(eval_losses)\n",
    "\n",
    "        # Eval image saving\n",
    "        ema_model.eval()\n",
    "        sample = torch.randn(config.eval_batch_size, 2).to(device)\n",
    "        timesteps = list(range(len(noise_scheduler)))[::-1]\n",
    "        inference_start_time = time.time()\n",
    "        for t in timesteps:\n",
    "            t = torch.from_numpy(np.repeat(t, config.eval_batch_size)).long().to(device)\n",
    "            with torch.no_grad():\n",
    "                residual = ema_model(sample, t)\n",
    "            sample = noise_scheduler.step(residual, t[0], sample)\n",
    "        sample = sample.cpu().numpy()\n",
    "        inference_end_time = time.time()\n",
    "        inference_time = inference_end_time - inference_start_time\n",
    "\n",
    "        # Eval estimated KL\n",
    "        real_data = dataset.tensors[0].numpy()\n",
    "        kl_divergence = ee.kldiv(real_data, sample, k=5)\n",
    "\n",
    "        final_infos[dataset_name] = {\n",
    "            \"means\": {\n",
    "                \"training_time\": training_time,\n",
    "                \"eval_loss\": eval_loss,\n",
    "                \"inference_time\": inference_time,\n",
    "                \"kl_divergence\": kl_divergence,\n",
    "            }\n",
    "        }\n",
    "\n",
    "        all_results[dataset_name] = {\n",
    "            \"train_losses\": train_losses,\n",
    "            \"images\": sample,\n",
    "        }\n",
    "\n",
    "    with open(osp.join(config.out_dir, \"final_info.json\"), \"w\") as f:\n",
    "        json.dump(final_infos, f)\n",
    "\n",
    "    with open(osp.join(config.out_dir, \"all_results.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(all_results, f)\n",
    "'''.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6219dc86-c715-479c-aab5-93532ed343fd",
   "metadata": {},
   "source": [
    "## Generate Ideas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a24dc1ba-f78a-467b-b040-f36c3cce31d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_idea_first = \"\"\"Generate research idea function\n",
    "\n",
    "Come up with the next impactful and creative idea for research experiments and directions you can feasibly investigate with the code provided.\n",
    "Note that you will not have access to any additional resources or datasets.\n",
    "Make sure any idea is not overfit the specific training dataset or model, and has wider significance.\n",
    "\n",
    "Args:\n",
    "    task_description: General Direction of Research.\n",
    "    experiment_code (str): Base experimental code.\n",
    "    prev_ideas (List[str], optional): Research ideas already considered.\n",
    "\n",
    "Returns:\n",
    "    thought (str): First briefly discuss your intuitions and motivations for the idea. Detail your high-level plan, necessary design choices and ideal outcomes of the experiments. Justify how the idea is different from the existing ones.\n",
    "    new_idea (str[xml]): New resarch idea in XML format. This value contains following tags.\n",
    "        - <Name>: A shortened descriptor of the idea. Lowercase, no spaces, underscores allowed.\n",
    "        - <Title>: A title for the idea, will be used for the report writing.\n",
    "        - <Experiment>: An outline of the implementation. E.g. which functions need to be added or modified, how results will be obtained, ...\n",
    "        - <Interestingness>: A rating from 1 to 10 (lowest to highest).\n",
    "        - <Feasibility>: A rating from 1 to 10 (lowest to highest).\n",
    "        - <Novelty>: A rating from 1 to 10 (lowest to highest).\n",
    "\"\"\".strip()\n",
    "\n",
    "compiled_idea_first = compiler.compile(source_idea_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3b8b593-427d-4c19-9235-356847c78365",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_idea_reflection = '''研究アイデアを洗練させる。\n",
    "\n",
    "研究アイデアが与えられる。そのアイデアは、以下の関数によって出力されたものである。\n",
    "\"\"\"Generate research idea function\n",
    "\n",
    "Come up with the next impactful and creative idea for research experiments and directions you can feasibly investigate with the code provided.\n",
    "Note that you will not have access to any additional resources or datasets.\n",
    "Make sure any idea is not overfit the specific training dataset or model, and has wider significance.\n",
    "\n",
    "Args:\n",
    "    task_description: General Direction of Research.\n",
    "    experiment_code (str): Base experimental code.\n",
    "    prev_ideas (List[str], optional): Research ideas already considered.\n",
    "\n",
    "Returns:\n",
    "    thought (str): First briefly discuss your intuitions and motivations for the idea. Detail your high-level plan, necessary design choices and ideal outcomes of the experiments. Justify how the idea is different from the existing ones.\n",
    "    new_idea (str[xml]): New resarch idea in XML format. This value contains following tags.\n",
    "        - <Name>: A shortened descriptor of the idea. Lowercase, no spaces, underscores allowed.\n",
    "        - <Title>: A title for the idea, will be used for the report writing.\n",
    "        - <Experiment>: An outline of the implementation. E.g. which functions need to be added or modified, how results will be obtained, ...\n",
    "        - <Interestingness>: A rating from 1 to 10 (lowest to highest).\n",
    "        - <Feasibility>: A rating from 1 to 10 (lowest to highest).\n",
    "        - <Novelty>: A rating from 1 to 10 (lowest to highest).\n",
    "\"\"\"\n",
    "\n",
    "このアイデアについて、品質、新規性、実現可能性を注意深く検討する。\n",
    "アイデアを評価する上で重要だと思われる他の要素も含める。\n",
    "ただし物事を複雑にしすぎることがないようにする。\n",
    "そのうえで、アイデアを洗練させ、改良する。\n",
    "目立つ問題がない限り、元のアイデアの精神にこだわらなければならない。\n",
    "\n",
    "Args:\n",
    "    task_description: General Direction of Research.\n",
    "    experiment_code (str): Base experimental code.\n",
    "    new_idea (str): 洗練・改良する対象の研究アイディア。\n",
    "    \n",
    "\n",
    "Returns:\n",
    "    new_idea_improved (str[xml]): 洗練された研究アイディア。\n",
    "        This value contains following tags.\n",
    "        - <Name>: A shortened descriptor of the idea. Lowercase, no spaces, underscores allowed.\n",
    "        - <Title>: A title for the idea, will be used for the report writing.\n",
    "        - <Experiment>: An outline of the implementation. E.g. which functions need to be added or modified, how results will be obtained, ...\n",
    "        - <Interestingness>: A rating from 1 to 10 (lowest to highest).\n",
    "        - <Feasibility>: A rating from 1 to 10 (lowest to highest).\n",
    "        - <Novelty>: A rating from 1 to 10 (lowest to highest).\n",
    "    improved (bool): 本質的な改善点があれば `True`, もはや洗練させる余地がなければ `False`.\n",
    "'''\n",
    "\n",
    "compiled_idea_reflection = compiler.compile(source_idea_reflection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d6721e8-6725-4fd0-b46d-777c081fb539",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_idea_first = CompiledLLMLink(llm_link, compiled_idea_first)\n",
    "func_idea_reflection = CompiledLLMLink(llm_link, compiled_idea_reflection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4edab8c-7250-4f40-9cdd-ed58f6952bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ideas(task_description, experiment_code,\n",
    "                   num_ideas=3, num_reflections=3):\n",
    "    ideas = []\n",
    "    for k in range(num_ideas):\n",
    "        print(f'Generate idea {k+1}.')\n",
    "        ret = func_idea_first(\n",
    "            task_description=task_description,\n",
    "            experiment_code=experiment_code,\n",
    "            prev_ideas=ideas)\n",
    "\n",
    "        ideas_k = [ret['new_idea'][0]]\n",
    "        print(f'Base idea :\\n{ideas_k[-1]}\\n\\n')\n",
    "\n",
    "        for i in range(num_reflections):\n",
    "            print(f'Round {i+1}/{num_reflections}.')\n",
    "            ret = func_idea_reflection(\n",
    "                task_description=task_description,\n",
    "                experiment_code=experiment_code,\n",
    "                new_idea=ideas_k)\n",
    "\n",
    "            if ret['improved'][0] == 'False':\n",
    "                print('改善の余地がない')\n",
    "                break\n",
    "    \n",
    "            ideas_k += [ret['new_idea_improved'][0]]\n",
    "            print(f'Improved idea :\\n{ideas_k[-1]}\\n\\n')\n",
    "\n",
    "        ideas += [ideas_k[-1]]\n",
    "\n",
    "    return ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b14338-04a0-4a6a-af2a-5225a7a66b50",
   "metadata": {},
   "source": [
    "### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f8515de-5eff-409a-acfc-cfd8de1499e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate idea 1.\n",
      "Base idea :\n",
      "<NAME>mode_aware_diffusion</NAME>\n",
      "<TITLE>Mode-Aware Noise Scheduling for Controllable Diffusion Model Generation</TITLE>\n",
      "<EXPERIMENT>\n",
      "Introduce a mode-aware noise scheduler:\n",
      "1. Extend the NoiseScheduler class to include a mode detection phase. This could involve clustering techniques or density estimation to identify prominent modes in the dataset.\n",
      "2. Implement a mechanism to adjust the noise addition process based on detected modes. This could involve varying the scale of noise or the progression of beta schedules for samples associated with different modes.\n",
      "3. Evaluate the impact of mode-aware scheduling on controllability by comparing generated samples with and without mode-awareness, analyzing diversity, and alignment with desired modes.\n",
      "4. Use existing datasets to assess improvements in mode-specific generation and overall performance metrics such as KL divergence and inference time.\n",
      "</EXPERIMENT>\n",
      "<INTERESTINGNESS>9</INTERESTINGNESS>\n",
      "<FEASIBILITY>7</FEASIBILITY>\n",
      "<NOVELTY>8</NOVELTY>\n",
      "\n",
      "\n",
      "Round 1/3.\n",
      "Improved idea :\n",
      "<NAME>enhanced_mode_aware_diffusion</NAME>\n",
      "<TITLE>Enhanced Mode-Aware Noise Scheduling for Efficient and Controllable Diffusion Model Generation</TITLE>\n",
      "<EXPERIMENT>\n",
      "Introduce an enhanced mode-aware noise scheduler:\n",
      "1. Extend the NoiseScheduler class to include an efficient mode detection phase using lightweight clustering or dimensionality reduction techniques.\n",
      "2. Implement a dynamic adjustment mechanism for the noise addition process, fine-tuning noise schedules based on real-time training performance feedback.\n",
      "3. Evaluate the impact of enhanced mode-aware scheduling by comparing generated samples with and without mode-awareness, focusing on diversity, mode alignment, computational efficiency, and stability.\n",
      "4. Use existing 2D datasets to assess improvements in mode-specific generation, overall performance metrics such as KL divergence, inference time, and training stability.\n",
      "</EXPERIMENT>\n",
      "<INTERESTINGNESS>9</INTERESTINGNESS>\n",
      "<FEASIBILITY>8</FEASIBILITY>\n",
      "<NOVELTY>8</NOVELTY>\n",
      "\n",
      "\n",
      "Round 2/3.\n",
      "Improved idea :\n",
      "<NAME>enhanced_mode_aware_diffusion_v2</NAME>\n",
      "<TITLE>Advanced Mode-Aware Noise Scheduling with Lightweight Techniques for Efficient and Controllable Diffusion Model Generation</TITLE>\n",
      "<EXPERIMENT>\n",
      "Introduce an advanced mode-aware noise scheduler with the following improvements:\n",
      "1. Utilize dimensionality reduction techniques like UMAP or t-SNE for efficient mode detection, reducing computational overhead.\n",
      "2. Implement a real-time feedback mechanism to adjust noise schedules dynamically, optimizing based on training performance.\n",
      "3. Focus on computational efficiency by using lightweight mode detection techniques and optimizing the noise adjustment process.\n",
      "4. Conduct a thorough evaluation using 2D datasets to compare mode-specific generation, performance metrics such as KL divergence, inference time, and training stability.\n",
      "5. Explore potential trade-offs between mode-specific quality improvement and computational requirements.\n",
      "</EXPERIMENT>\n",
      "<INTERESTINGNESS>9</INTERESTINGNESS>\n",
      "<FEASIBILITY>9</FEASIBILITY>\n",
      "<NOVELTY>9</NOVELTY>\n",
      "\n",
      "\n",
      "Round 3/3.\n",
      "Improved idea :\n",
      "<NAME>advanced_mode_aware_diffusion_v3</NAME>\n",
      "<TITLE>Comprehensive Mode-Aware Noise Scheduling for Efficient and Controllable Diffusion Model Generation</TITLE>\n",
      "<EXPERIMENT>\n",
      "Introduce a comprehensive mode-aware noise scheduler with the following improvements:\n",
      "1. Utilize a broad range of lightweight dimensionality reduction techniques like UMAP, t-SNE, and PCA for adaptable mode detection, tailored to dataset characteristics.\n",
      "2. Implement a sophisticated real-time feedback mechanism using model loss, mode overlap, and generation diversity metrics to dynamically optimize noise schedules.\n",
      "3. Focus on computational efficiency by refining lightweight mode detection techniques and optimizing the noise adjustment process.\n",
      "4. Conduct a thorough evaluation using 2D datasets, comparing mode-specific generation, performance metrics such as KL divergence, inference time, training stability, robustness to noise, and adaptability to different datasets.\n",
      "5. Explore potential trade-offs between mode-specific quality improvement, computational requirements, and scalability to higher-dimensional datasets.\n",
      "</EXPERIMENT>\n",
      "<INTERESTINGNESS>9</INTERESTINGNESS>\n",
      "<FEASIBILITY>9</FEASIBILITY>\n",
      "<NOVELTY>9</NOVELTY>\n",
      "\n",
      "\n",
      "Generate idea 2.\n",
      "Base idea :\n",
      "<NAME>multi_scale_encoding_diffusion</NAME>\n",
      "<TITLE>Multi-Scale Encoding and Control Mechanisms for Enhanced Diffusion Model Generation</TITLE>\n",
      "<EXPERIMENT>\n",
      "1. Develop and integrate alternative encoding methods like wavelet and Fourier transforms for enhanced feature representation.\n",
      "2. Implement a multi-scale architecture where different network layers capture varying levels of detail.\n",
      "3. Introduce control variables that allow explicit manipulation of data modes during generation, enhancing the controllable generation aspect.\n",
      "4. Evaluate the approach on 2D datasets and measure the diversity, quality, and control over generated samples, comparing against baseline sinusoidal encoding.\n",
      "5. Analyze computational overhead and scaling potential of the new encoding and control mechanisms.\n",
      "</EXPERIMENT>\n",
      "<INTERESTINGNESS>10</INTERESTINGNESS>\n",
      "<FEASIBILITY>7</FEASIBILITY>\n",
      "<NOVELTY>8</NOVELTY>\n",
      "\n",
      "\n",
      "Round 1/3.\n",
      "Improved idea :\n",
      "<NAME>enhanced_multi_scale_encoding_diffusion</NAME>\n",
      "<TITLE>Enhanced Multi-Scale Encoding with Control Framework for Diffusion Model Generation</TITLE>\n",
      "<EXPERIMENT>\n",
      "1. Develop a hybrid encoding approach that combines sinusoidal encoding with wavelet or Fourier transforms, leveraging their complementary strengths.\n",
      "2. Implement a multi-scale architecture with attention mechanisms to dynamically capture varying levels of detail across network layers.\n",
      "3. Design a control framework that allows flexible manipulation of data modes, incorporating user input or automated mode selection.\n",
      "4. Evaluate the model on 2D datasets with an expanded set of metrics, including computational efficiency, scalability, and robustness.\n",
      "5. Analyze the applicability of the approach in various domains, such as image synthesis and pattern recognition, emphasizing its potential impact.\n",
      "6. Implement the approach in a phased manner, starting with individual components and progressing to integrated testing, allowing for iterative refinement.\n",
      "</EXPERIMENT>\n",
      "<INTERESTINGNESS>10</INTERESTINGNESS>\n",
      "<FEASIBILITY>8</FEASIBILITY>\n",
      "<NOVELTY>9</NOVELTY>\n",
      "\n",
      "\n",
      "Round 2/3.\n",
      "Improved idea :\n",
      "<NAME>enhanced_multi_scale_encoding_diffusion_improved</NAME>\n",
      "<TITLE>Enhanced Multi-Scale Encoding with Control Framework for Diffusion Model Generation</TITLE>\n",
      "<EXPERIMENT>\n",
      "1. Develop a hybrid encoding approach that combines sinusoidal encoding with wavelet or Fourier transforms, leveraging their complementary strengths for diverse 2D datasets.\n",
      "2. Implement a multi-scale architecture with attention mechanisms to dynamically capture varying levels of detail across network layers, focusing on applications in image synthesis and pattern recognition.\n",
      "3. Design a robust control framework that allows flexible manipulation of data modes, incorporating user input or automated mode selection, enhancing controllable generation.\n",
      "4. Evaluate the model on 2D datasets with an expanded set of metrics, including computational efficiency, scalability, robustness, and potential application impact.\n",
      "5. Implement the approach in a phased manner, starting with individual components and progressing to integrated testing, allowing for iterative refinement and validation.\n",
      "</EXPERIMENT>\n",
      "<INTERESTINGNESS>10</INTERESTINGNESS>\n",
      "<FEASIBILITY>8</FEASIBILITY>\n",
      "<NOVELTY>9</NOVELTY>\n",
      "\n",
      "\n",
      "Round 3/3.\n",
      "Improved idea :\n",
      "<NAME>enhanced_multi_scale_encoding_diffusion_final</NAME>\n",
      "<TITLE>Enhanced Multi-Scale Encoding with Control Framework for Diffusion Model Generation</TITLE>\n",
      "<EXPERIMENT>\n",
      "1. Develop a hybrid encoding approach that combines sinusoidal encoding with wavelet or Fourier transforms, leveraging their complementary strengths for diverse 2D datasets.\n",
      "2. Implement a multi-scale architecture with attention mechanisms to dynamically capture varying levels of detail across network layers, focusing on applications in image synthesis and pattern recognition.\n",
      "3. Design a robust control framework that allows flexible manipulation of data modes, incorporating user input or automated mode selection, enhancing controllable generation.\n",
      "4. Evaluate the model on 2D datasets with an expanded set of metrics, including computational efficiency, scalability, robustness, and potential application impact.\n",
      "5. Implement the approach in a phased manner, starting with individual components and progressing to integrated testing, allowing for iterative refinement and validation.\n",
      "6. Explore additional applications in domains like video generation and medical imaging, where enhanced encoding and control could be beneficial.\n",
      "</EXPERIMENT>\n",
      "<INTERESTINGNESS>10</INTERESTINGNESS>\n",
      "<FEASIBILITY>8</FEASIBILITY>\n",
      "<NOVELTY>9</NOVELTY>\n",
      "\n",
      "\n",
      "Generate idea 3.\n",
      "Base idea :\n",
      "<NAME>geometric_encoding_adaptive_control_diffusion</NAME>\n",
      "<TITLE>Geometric Encoding with Adaptive Control Mechanism for Enhanced Diffusion Model Performance</TITLE>\n",
      "<EXPERIMENT>\n",
      "1. Develop a geometric encoding module that transforms 2D data into a graph-based representation, capturing spatial relationships and complex patterns.\n",
      "2. Integrate this module into the existing diffusion model framework, replacing or augmenting the sinusoidal encoding process.\n",
      "3. Implement an adaptive control mechanism that learns data modes dynamically during training, allowing for real-time adjustments to the generation process.\n",
      "4. Evaluate the model's performance on 2D datasets, focusing on improvements in generation quality, controllability, and computational efficiency.\n",
      "5. Compare results with previous models using metrics like KL divergence, inference time, and training stability, providing insights into the benefits of geometric encoding and adaptive control.\n",
      "6. Explore potential applications in domains requiring complex pattern recognition, such as topology analysis or network data visualization.\n",
      "</EXPERIMENT>\n",
      "<INTERESTINGNESS>9</INTERESTINGNESS>\n",
      "<FEASIBILITY>8</FEASIBILITY>\n",
      "<NOVELTY>10</NOVELTY>\n",
      "\n",
      "\n",
      "Round 1/3.\n",
      "Improved idea :\n",
      "<NAME>geometric_encoding_adaptive_control_diffusion_improved</NAME>\n",
      "<TITLE>Enhanced Diffusion Model with Geometric Encoding and Adaptive Control for 2D Data Generation</TITLE>\n",
      "<EXPERIMENT>\n",
      "1. Design a geometric encoding module that transforms 2D data into graph-based representations, focusing on preserving spatial relationships and capturing complex patterns.\n",
      "2. Integrate the encoding module into the diffusion model, evaluating whether to replace or augment the existing sinusoidal encoding.\n",
      "3. Develop a lightweight adaptive control mechanism that dynamically learns and adjusts data modes during training, ensuring minimal computational overhead.\n",
      "4. Conduct experiments on 2D datasets to assess improvements in generation quality, controllability, and computational efficiency.\n",
      "5. Compare the enhanced model's performance with benchmarks, using metrics like KL divergence, inference time, and training stability.\n",
      "6. Investigate applications in fields requiring advanced pattern recognition, such as network analysis or topological data exploration.\n",
      "7. Explore the adaptability of the geometric encoding and adaptive control approach to other low-dimensional data types.\n",
      "</EXPERIMENT>\n",
      "<INTERESTINGNESS>9</INTERESTINGNESS>\n",
      "<FEASIBILITY>8</FEASIBILITY>\n",
      "<NOVELTY>10</NOVELTY>\n",
      "\n",
      "\n",
      "Round 2/3.\n",
      "Improved idea :\n",
      "<NAME>geometric_encoding_adaptive_control_diffusion_improved</NAME>\n",
      "<TITLE>Enhanced Diffusion Model with Geometric Encoding and Adaptive Control for 2D Data Generation</TITLE>\n",
      "<EXPERIMENT>\n",
      "1. Design a geometric encoding module that transforms 2D data into graph-based representations, focusing on preserving spatial relationships and capturing complex patterns.\n",
      "2. Integrate the encoding module into the diffusion model, evaluating whether to replace or augment the existing sinusoidal encoding.\n",
      "3. Develop a lightweight adaptive control mechanism that dynamically learns and adjusts data modes during training, ensuring minimal computational overhead.\n",
      "4. Conduct experiments on 2D datasets to assess improvements in generation quality, controllability, and computational efficiency.\n",
      "5. Compare the enhanced model's performance with benchmarks, using metrics like KL divergence, inference time, and training stability.\n",
      "6. Investigate applications in fields requiring advanced pattern recognition, such as network analysis or topological data exploration.\n",
      "7. Explore the adaptability of the geometric encoding and adaptive control approach to other low-dimensional data types.\n",
      "</EXPERIMENT>\n",
      "<INTERESTINGNESS>9</INTERESTINGNESS>\n",
      "<FEASIBILITY>8</FEASIBILITY>\n",
      "<NOVELTY>10</NOVELTY>\n",
      "\n",
      "\n",
      "Round 3/3.\n",
      "Improved idea :\n",
      "<NAME>enhanced_geometric_encoding_adaptive_control_diffusion</NAME>\n",
      "<TITLE>Enhanced Diffusion Models with Geometric Encoding and Adaptive Control Mechanism for 2D Data</TITLE>\n",
      "<EXPERIMENT>\n",
      "1. Develop a geometric encoding module for transforming 2D data into graph-based representations, preserving spatial relationships and capturing complex patterns.\n",
      "2. Integrate this module into the diffusion model, evaluating whether to replace or augment sinusoidal encoding.\n",
      "3. Implement a lightweight adaptive control mechanism using reinforcement learning, allowing dynamic learning and adjustments of data modes during training.\n",
      "4. Conduct experiments on 2D datasets to assess improvements in generation quality, controllability, and computational efficiency.\n",
      "5. Benchmark the model's performance using metrics such as KL divergence, inference time, training stability, and additional metrics for generation quality.\n",
      "6. Investigate applications in fields requiring advanced pattern recognition, such as network analysis and topological data exploration.\n",
      "7. Explore the adaptability of the geometric encoding and adaptive control approach to other low-dimensional data types.\n",
      "</EXPERIMENT>\n",
      "<INTERESTINGNESS>9</INTERESTINGNESS>\n",
      "<FEASIBILITY>8</FEASIBILITY>\n",
      "<NOVELTY>10</NOVELTY>\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<NAME>advanced_mode_aware_diffusion_v3</NAME>\\n<TITLE>Comprehensive Mode-Aware Noise Scheduling for Efficient and Controllable Diffusion Model Generation</TITLE>\\n<EXPERIMENT>\\nIntroduce a comprehensive mode-aware noise scheduler with the following improvements:\\n1. Utilize a broad range of lightweight dimensionality reduction techniques like UMAP, t-SNE, and PCA for adaptable mode detection, tailored to dataset characteristics.\\n2. Implement a sophisticated real-time feedback mechanism using model loss, mode overlap, and generation diversity metrics to dynamically optimize noise schedules.\\n3. Focus on computational efficiency by refining lightweight mode detection techniques and optimizing the noise adjustment process.\\n4. Conduct a thorough evaluation using 2D datasets, comparing mode-specific generation, performance metrics such as KL divergence, inference time, training stability, robustness to noise, and adaptability to different datasets.\\n5. Explore potential trade-offs between mode-specific quality improvement, computational requirements, and scalability to higher-dimensional datasets.\\n</EXPERIMENT>\\n<INTERESTINGNESS>9</INTERESTINGNESS>\\n<FEASIBILITY>9</FEASIBILITY>\\n<NOVELTY>9</NOVELTY>',\n",
       " '<NAME>enhanced_multi_scale_encoding_diffusion_final</NAME>\\n<TITLE>Enhanced Multi-Scale Encoding with Control Framework for Diffusion Model Generation</TITLE>\\n<EXPERIMENT>\\n1. Develop a hybrid encoding approach that combines sinusoidal encoding with wavelet or Fourier transforms, leveraging their complementary strengths for diverse 2D datasets.\\n2. Implement a multi-scale architecture with attention mechanisms to dynamically capture varying levels of detail across network layers, focusing on applications in image synthesis and pattern recognition.\\n3. Design a robust control framework that allows flexible manipulation of data modes, incorporating user input or automated mode selection, enhancing controllable generation.\\n4. Evaluate the model on 2D datasets with an expanded set of metrics, including computational efficiency, scalability, robustness, and potential application impact.\\n5. Implement the approach in a phased manner, starting with individual components and progressing to integrated testing, allowing for iterative refinement and validation.\\n6. Explore additional applications in domains like video generation and medical imaging, where enhanced encoding and control could be beneficial.\\n</EXPERIMENT>\\n<INTERESTINGNESS>10</INTERESTINGNESS>\\n<FEASIBILITY>8</FEASIBILITY>\\n<NOVELTY>9</NOVELTY>',\n",
       " \"<NAME>enhanced_geometric_encoding_adaptive_control_diffusion</NAME>\\n<TITLE>Enhanced Diffusion Models with Geometric Encoding and Adaptive Control Mechanism for 2D Data</TITLE>\\n<EXPERIMENT>\\n1. Develop a geometric encoding module for transforming 2D data into graph-based representations, preserving spatial relationships and capturing complex patterns.\\n2. Integrate this module into the diffusion model, evaluating whether to replace or augment sinusoidal encoding.\\n3. Implement a lightweight adaptive control mechanism using reinforcement learning, allowing dynamic learning and adjustments of data modes during training.\\n4. Conduct experiments on 2D datasets to assess improvements in generation quality, controllability, and computational efficiency.\\n5. Benchmark the model's performance using metrics such as KL divergence, inference time, training stability, and additional metrics for generation quality.\\n6. Investigate applications in fields requiring advanced pattern recognition, such as network analysis and topological data exploration.\\n7. Explore the adaptability of the geometric encoding and adaptive control approach to other low-dimensional data types.\\n</EXPERIMENT>\\n<INTERESTINGNESS>9</INTERESTINGNESS>\\n<FEASIBILITY>8</FEASIBILITY>\\n<NOVELTY>10</NOVELTY>\"]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ideas = generate_ideas(task_description, experiment_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb65c4b-9d87-4763-b637-25f2fdf3e73e",
   "metadata": {},
   "source": [
    "## Check Idea Novelty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f381a72-3cca-4e4d-929b-2e8c09851293",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
